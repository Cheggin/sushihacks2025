{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "697069e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.0.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/shawnpana/Documents/GitHub/sushihacks2025/backend/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Downloading openai-2.0.0-py3-none-any.whl (955 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m955.5/955.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.11.0-cp312-cp312-macosx_11_0_arm64.whl (316 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.11.0 openai-2.0.0 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d4a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4f27489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/shawnpana/Documents/GitHub/sushihacks2025/backend/data/occurrence_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a9f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# in a csv file called output.csv, write the unique values of the column 'scientificName', one per line\n",
    "df['scientificName'].drop_duplicates().to_csv('/Users/shawnpana/Documents/GitHub/sushihacks2025/backend/data/output.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06619e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First install openai if not already installed\n",
    "# Run this in terminal: pip install openai\n",
    "\n",
    "# Fish Classification using OpenAI API\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Check if openai is installed\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    print(\"‚úÖ OpenAI library is installed\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå OpenAI library not found. Please install it with: pip install openai\")\n",
    "    print(\"After installing, restart the kernel and run this cell again\")\n",
    "    raise\n",
    "\n",
    "# Initialize OpenAI client\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è Warning: OPENAI_API_KEY environment variable not set\")\n",
    "    print(\"Set it with: export OPENAI_API_KEY='your-key-here'\")\n",
    "else:\n",
    "    print(\"‚úÖ API key found\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def classify_fish(scientific_name: str):\n",
    "    \"\"\"Classify a single fish species using GPT-4\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are a marine biology and culinary expert. Classify fish species accurately based on scientific knowledge and fisheries data. Respond with EXACTLY 6 values separated by pipe symbols (|). No extra text.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": f\"\"\"Classify the fish species '{scientific_name}':\n",
    "1. Cleaning Difficulty: easy, medium, or hard\n",
    "2. Market Commonality: common, uncommon, or rare\n",
    "3. General Availability: year-round, seasonal, or rarely-available\n",
    "4. Peak Season: ONLY format as Month-Month (e.g., \"June-August\" or \"December-February\" or \"Year-Round\" if available all year)\n",
    "5. Is Edible: yes or no (consider if safe for human consumption)\n",
    "6. Primary Data Source: The main source for this information (e.g., \"FAO Fisheries\", \"NOAA Database\", \"FishBase\", \"SeaLifeBase\", \"Marine Biology Research\", \"General Knowledge\")\n",
    "\n",
    "Format EXACTLY as: difficulty|commonality|availability|peak_season|edible|source\n",
    "Example: medium|common|seasonal|June-September|yes|FAO Fisheries\"\"\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=60\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content.strip()\n",
    "        parts = [x.strip() for x in result.split('|')]\n",
    "        \n",
    "        if len(parts) != 6:\n",
    "            print(f\"  ‚ö†Ô∏è Unexpected format for {scientific_name}: {result}\")\n",
    "            return ['unknown', 'unknown', 'unknown', 'unknown', False, 'GPT-4 Estimation']\n",
    "        \n",
    "        # Format peak season properly (capitalize months)\n",
    "        peak_season = parts[3]\n",
    "        if peak_season.lower() != 'year-round':\n",
    "            # Capitalize first letter of each word for months\n",
    "            peak_season = '-'.join([month.capitalize() for month in peak_season.split('-')])\n",
    "        else:\n",
    "            peak_season = 'Year-Round'\n",
    "        \n",
    "        # Convert edibility to boolean\n",
    "        is_edible = parts[4].lower() in ['yes', 'edible', 'true', '1']\n",
    "        \n",
    "        # Clean up source name\n",
    "        source = parts[5] if parts[5] else 'GPT-4 Knowledge Base'\n",
    "        \n",
    "        return [parts[0].lower(), parts[1].lower(), parts[2].lower(), peak_season, is_edible, source]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error with {scientific_name}: {str(e)[:50]}\")\n",
    "        return ['error', 'error', 'error', 'error', False, 'Error']\n",
    "\n",
    "# Process fish species\n",
    "output_rows = []\n",
    "csv_path = '/Users/shawnpana/Documents/GitHub/sushihacks2025/backend/data/output.csv'\n",
    "\n",
    "try:\n",
    "    # Read species names (skip header if present)\n",
    "    df_species = pd.read_csv(csv_path)\n",
    "    scientific_names = df_species['scientificName'].tolist() if 'scientificName' in df_species.columns else df_species.iloc[:, 0].tolist()\n",
    "    \n",
    "    total_species = len(scientific_names)\n",
    "    print(f\"\\nüìä Processing ALL {total_species} fish species...\")\n",
    "    print(\"Will classify: cleaning difficulty, commonality, seasonality, peak season, edibility, and source\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    # Process ALL species\n",
    "    for i, name in enumerate(scientific_names, 1):\n",
    "        print(f\"{i:4d}/{total_species}. {name[:30]:<30}\", end=\" \")\n",
    "        \n",
    "        parts = classify_fish(name)\n",
    "        output_rows.append({\n",
    "            'scientificName': name,\n",
    "            'cleaning_difficulty': parts[0],\n",
    "            'commonality': parts[1],\n",
    "            'seasonality': parts[2],\n",
    "            'peak_season': parts[3],  # Format: \"June-August\" or \"Year-Round\"\n",
    "            'is_edible': parts[4],  # Boolean: True or False\n",
    "            'data_source': parts[5],  # Source of information\n",
    "            'classification_date': datetime.now().strftime('%Y-%m-%d')  # When classified\n",
    "        })\n",
    "        \n",
    "        # Shorter output with emoji indicators\n",
    "        edible_emoji = \"‚úÖ\" if parts[4] else \"‚ùå\"\n",
    "        source_short = parts[5][:15] if len(parts[5]) > 15 else parts[5]\n",
    "        print(f\"‚Üí {parts[3][:12]:<12} {edible_emoji} [{source_short}]\")\n",
    "        \n",
    "        # Rate limiting to avoid hitting API rate limits\n",
    "        if i % 3 == 0:\n",
    "            time.sleep(0.5)  # Small delay every 3 requests\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            # Save intermediate progress every 50 species\n",
    "            df_temp = pd.DataFrame(output_rows)\n",
    "            df_temp.to_csv('/Users/shawnpana/Documents/GitHub/sushihacks2025/backend/data/fish_classification_temp.csv', index=False)\n",
    "            print(f\"  üíæ Saved progress: {i}/{total_species} species processed\")\n",
    "            time.sleep(2)  # Longer pause every 50 to avoid rate limits\n",
    "    \n",
    "    # Save final results\n",
    "    df_output = pd.DataFrame(output_rows)\n",
    "    output_path = '/Users/shawnpana/Documents/GitHub/sushihacks2025/backend/data/fish_classification.csv'\n",
    "    df_output.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(\"-\" * 90)\n",
    "    print(f\"‚úÖ Successfully classified ALL {len(output_rows)} fish species!\")\n",
    "    print(f\"üìÑ Results saved to: fish_classification.csv\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nüìä Summary Statistics:\")\n",
    "    print(f\"  Edible fish: {df_output['is_edible'].sum()} ({(df_output['is_edible'].sum()/len(df_output)*100):.1f}%)\")\n",
    "    print(f\"  Non-edible fish: {(~df_output['is_edible']).sum()} ({((~df_output['is_edible']).sum()/len(df_output)*100):.1f}%)\")\n",
    "    print(f\"  Year-round availability: {(df_output['seasonality'] == 'year-round').sum()}\")\n",
    "    print(f\"  Seasonal fish: {(df_output['seasonality'] == 'seasonal').sum()}\")\n",
    "    \n",
    "    # Data source breakdown\n",
    "    print(\"\\nüìö Data Sources Used:\")\n",
    "    source_counts = df_output['data_source'].value_counts()\n",
    "    for source, count in source_counts.head(10).items():\n",
    "        print(f\"  {source}: {count} species ({count/len(df_output)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüêü Sample Results:\")\n",
    "    sample_cols = ['scientificName', 'peak_season', 'is_edible', 'data_source']\n",
    "    print(df_output[sample_cols].head(10))\n",
    "    \n",
    "    # Show some edible seasonal fish\n",
    "    print(\"\\nüé£ Sample of Edible Seasonal Fish:\")\n",
    "    seasonal_edible = df_output[(df_output['is_edible'] == True) & (df_output['seasonality'] == 'seasonal')]\n",
    "    if len(seasonal_edible) >= 5:\n",
    "        print(seasonal_edible[['scientificName', 'peak_season', 'commonality', 'data_source']].sample(min(5, len(seasonal_edible))))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {csv_path}\")\n",
    "    print(\"Run the previous cells to create output.csv first\")\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\n‚ö†Ô∏è Process interrupted! Processed {len(output_rows)} species so far\")\n",
    "    if output_rows:\n",
    "        df_partial = pd.DataFrame(output_rows)\n",
    "        df_partial.to_csv('/Users/shawnpana/Documents/GitHub/sushihacks2025/backend/data/fish_classification_partial.csv', index=False)\n",
    "        print(f\"üíæ Partial results saved to fish_classification_partial.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    if output_rows:\n",
    "        df_error = pd.DataFrame(output_rows)\n",
    "        df_error.to_csv('/Users/shawnpana/Documents/GitHub/sushihacks2025/backend/data/fish_classification_error.csv', index=False)\n",
    "        print(f\"üíæ Results before error saved to fish_classification_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbf0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
